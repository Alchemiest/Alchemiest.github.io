<!DOCTYPE html>
<html lang="zh-cn">
  <head>
    <meta charset="utf8" />
    <meta name="viewport" content="initial-scale=1.0, width=device-width" />
    <title>
      
        深度学习——卷积神经网络——NiN | 科学炼丹
      
    </title>
    <meta name="description" content="由Hexo及华为云驱动"/>
    <meta name="keywords" content=""/>
    
      <link rel="apple-touch-icon"
            sizes="180x180"
            href="/images/apple-touch-icon.png"/>
    
    
      <link rel="icon"
            type="image/png"
            sizes="32x32"
            href="/images/favicon-32x32.png"/>
    
    
      <link rel="icon"
            type="image/png"
            sizes="16x16"
            href="/images/favicon-16x16.png"/>
    
    
      <link rel="mask-icon"
            href="/images/logo.svg"
            color=""/>
    
    
    <link rel="stylesheet" type="text/css" href="/css/layout.css"/>
    
    
  <link rel="stylesheet" type="text/css" href="/css/post.css"/>
  <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css"/>

  <meta name="generator" content="Hexo 6.3.0"></head>
  <body>
    <div class="head">
      <div class="nav">
        <a href="/" class="nav-logo">
          <img alt="logo" height="60px" width="60px" src="/images/logo.svg" />
        </a>
        <input id="navBtn" type="checkbox"/>
        <div class="nav-menu">
          
            
              <a class="nav-menu-item" href="/ability_DA">数据分析</a>
            
              <a class="nav-menu-item" href="/ability_DL">深度学习</a>
            
              <a class="nav-menu-item" href="/award">学习经历</a>
            
              <a class="nav-menu-item" href="/honor">学术成就</a>
            
          
        </div>
        <label class="nav-btn" for="navBtn"></label>
      </div>
    </div>
    <div class="body">
      
  <article class="post-content">
    <div class="post-inner">
      <div class="post-content__head">
        <div class="post-title">深度学习——卷积神经网络——NiN</div>
        <div class="post-info">
          
  
    <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-tag">#深度学习</a>
  
    <a href="/tags/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" class="post-tag">#卷积神经网络</a>
  
    <a href="/tags/%E5%8D%95GPU%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/" class="post-tag">#单GPU训练模型</a>
  
    <a href="/tags/NiN/" class="post-tag">#NiN</a>
  


          <span class="post-date">2022-04-20</span>
        </div>
      </div>
      <div id="postBody" class="post-content__body--toc">
        <div id="tocAnchor" class="toc-anchor">
          <ol id="toc" class="post-toc">
            
              <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#NiN"><span class="toc-text">NiN</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#NiN%E5%9D%97"><span class="toc-text">NiN块</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#NiN%E6%9E%B6%E6%9E%84"><span class="toc-text">NiN架构</span></a></li></ol>
            
          </ol>
        </div>
        
          <div class="post-gallery">
            
          </div>
        
        <p>摘要: 本节内容主要讲述卷积神经网络的NiN</p>
<span id="more"></span>
<h2 id="NiN"><a href="#NiN" class="headerlink" title="NiN"></a>NiN</h2><p>LeNet、AlexNet和VGG都有一个共同的设计模式：通过一系列的卷积层与汇聚层来提取空间结构特征；然后通过全连接层对特征的表征进行处理。 AlexNet和VGG对LeNet的改进主要在于如何扩大和加深这两个模块。 或者，可以想象在这个过程的早期使用全连接层。然而，如果使用了全连接层，可能会完全放弃表征的空间结构。 网络中的网络（NiN）提供了一个非常简单的解决方案：在每个像素的通道上分别使用多层感知机。<br>全连接层的问题：卷积层需要较少的参数，但是卷积层之后的第一个全连接层的参数非常的多，这就导致卷积层之后的第一个全连接层很容易带来过拟合的问题，针对这一层的过拟合的问题需要做大量的正则化来避免这一层把所有的要学习的东西都学习了，过拟合了。一个网络占用的内存的大头就是卷积层之后的第一个全连接层所带来的内存的占用。大量的参数一方面会占用大量的内存，另一方面会占用大量的计算带宽。<br>NiN针对这样的问题，其解决的思想就是完全不要全连接层。<br>softmax已经集成在train_ch6里面了</p>
<h2 id="NiN块"><a href="#NiN块" class="headerlink" title="NiN块"></a>NiN块</h2><p>回想一下，卷积层的输入和输出由四维张量组成，张量的每个轴分别对应样本、通道、高度和宽度。另外，全连接层的输入和输出通常是分别对应于样本和特征的二维张量。NiN的想法是在每个像素位置（针对每个高度和宽度）应用一个全连接层。如果我们将权重连接到每个空间位置，我们可以将其视为1x1卷积层，或作为在每个像素位置上独立作用的全连接层。<br>从另一个角度看，即将空间维度中的每个像素视为单个样本，将通道维度视为不同特征（feature）。NiN块以一个普通卷积层开始，后面是两个1x1的卷积层。这两个1x1卷积层充当带有ReLU激活函数的逐像素全连接层。第一层的卷积窗口形状通常由用户设置。随后的卷积窗口形状固定为1x1。一个卷积层后跟两个1x1的卷积层（全连接层），步幅为1，无填充，输出形状跟卷积层输出一样，起到全连接层的作用。一个NiN块其实就可以看作是一个非常简单的卷积神经网络（一个卷积层加两个全连接层）</p>
<h2 id="NiN架构"><a href="#NiN架构" class="headerlink" title="NiN架构"></a>NiN架构</h2><p>全局池化层是指池化层的高宽等于输入的高宽，等价于说把每一个通道最大的值给取出来。全局池化层的输入通道数量就是类别数，所以把每一个通道的最大值取出来，把这个值当作对这个类别的预测，最后套一层softmax就是最后预测的概率了。<br>最初的NiN网络是在AlexNet后不久提出的，显然从中得到了一些启示。 NiN使用窗口形状为11×11、5×5和3×3的卷积层，输出通道数量与AlexNet中的相同。 每个NiN块后有一个最大汇聚层，汇聚窗口形状为3×3，步幅为2。<br>NiN和AlexNet之间的一个显著区别是NiN完全取消了全连接层。 相反，NiN使用一个NiN块，其输出通道数等于标签类别的数量。最后放一个全局平均汇聚层（global average pooling layer），生成一个对数几率 （logits）。NiN设计的一个优点是，它显著减少了模型所需参数的数量。然而，在实践中，这种设计有时会增加训练模型的时间。</p>
<ul>
<li>无全连接层</li>
<li>交替使用NiN块和步幅为2的最大池化层：逐步减小高宽和最大通道数</li>
<li>最后使用全局平均池化层得到输出：其输入通道是类别数<br>总结</li>
<li>NiN块使用卷积层加两个1x1卷积层，后者对每个像素增加了非线性性</li>
<li>NiN使用全局平均池化层来替代VGG和AlexNet中的全连接层：不容易过拟合以及更少的参数个数<br>AlexNet是更大更深的LeNet，NiN是更大更深的AlexNet。</li>
</ul>
<hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#定义NiN块</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">nin_block</span>(<span class="params">in_channels, out_channels, kernel_size, strides, padding</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    定义每一个NiN块输入的通道数量、输出的通道数量，第一个卷积层的kernel的大小等等</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(</span><br><span class="line">        nn.Conv2d(in_channels, out_channels, kernel_size, strides, padding),</span><br><span class="line">        nn.ReLU(),</span><br><span class="line">        nn.Conv2d(out_channels, out_channels, kernel_size=<span class="number">1</span>), nn.ReLU(),</span><br><span class="line">        nn.Conv2d(out_channels, out_channels, kernel_size=<span class="number">1</span>), nn.ReLU())</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义网络</span></span><br><span class="line">net = nn.Sequential(</span><br><span class="line">    nin_block(<span class="number">1</span>, <span class="number">96</span>, kernel_size=<span class="number">11</span>, strides=<span class="number">4</span>, padding=<span class="number">0</span>),</span><br><span class="line">    nn.MaxPool2d(<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nin_block(<span class="number">96</span>, <span class="number">256</span>, kernel_size=<span class="number">5</span>, strides=<span class="number">1</span>, padding=<span class="number">2</span>),</span><br><span class="line">    nn.MaxPool2d(<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nin_block(<span class="number">256</span>, <span class="number">384</span>, kernel_size=<span class="number">3</span>, strides=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">    nn.MaxPool2d(<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">    nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">    <span class="comment"># 标签类别数是10</span></span><br><span class="line">    nin_block(<span class="number">384</span>, <span class="number">10</span>, kernel_size=<span class="number">3</span>, strides=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">    nn.AdaptiveAvgPool2d((<span class="number">1</span>, <span class="number">1</span>)),</span><br><span class="line">    <span class="comment"># 将四维的输出转成二维的输出，其形状为(批量大小,10)</span></span><br><span class="line">    nn.Flatten())</span><br><span class="line"></span><br><span class="line"><span class="comment">#检查模型</span></span><br><span class="line">X = torch.rand(size=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> net:</span><br><span class="line">    X = layer(X)</span><br><span class="line">    <span class="built_in">print</span>(layer.__class__.__name__,<span class="string">&#x27;output shape:\t&#x27;</span>, X.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment">#读取数据，训练模型</span></span><br><span class="line">lr, num_epochs, batch_size = <span class="number">0.1</span>, <span class="number">10</span>, <span class="number">128</span></span><br><span class="line">train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=<span class="number">224</span>)</span><br><span class="line">d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, <span class="string">&#x27;mps&#x27;</span>)</span><br></pre></td></tr></table></figure>

<hr>

      </div>
    </div>
  </article>
  <div class="post__foot">
    
      <div class="like-author">
  <input type="checkbox" id="likeCode" />
  <div class="author-face">
    <img height="100px"
         width="100px"
         id="front-face"
         alt="author face"
         src="/images/IMG_5172.JPG# 头像图片"/>
    <img height="100px"
         width="100px"
         id="back-face"
         alt="like code"
         src="/images/IMG_3538.jpg# 支付码图片"/>
  </div>
  <div class="like-text">“请作者喝杯咖啡”</div>
  <label for="likeCode" class="like-btn">
    <svg viewBox="0 0 1024 1024"
         width="20px"
         style="margin-right: 10px"
         height="20px">
      <path d="M466.88 908.96L113.824 563.296a270.08 270.08 0 0 1 0-387.392c108.8-106.56 284.896-106.56 393.696 0 1.504 1.472 2.976 2.944 4.448 4.48 1.472-1.536 2.944-3.008 4.448-4.48 108.8-106.56 284.896-106.56 393.696 0a269.952 269.952 0 0 1 34.016 347.072l-387.392 385.6a64 64 0 0 1-89.92 0.384z" p-id="13650" fill="#ee4242"/>
    </svg>
    喜欢作者
  </label>
</div>

    
    <div class="post-nav">
  
    <a class="post-nav-item-left" href="/2022/05/20/GoogLeNet/">
      <div class="text-align">
        <svg t="1670570876164"
             class="icon"
             viewBox="0 0 1024 1024"
             width="16"
             height="16">
          <path d="M384 512L731.733333 202.666667c17.066667-14.933333 19.2-42.666667 4.266667-59.733334-14.933333-17.066667-42.666667-19.2-59.733333-4.266666l-384 341.333333c-10.666667 8.533333-14.933333 19.2-14.933334 32s4.266667 23.466667 14.933334 32l384 341.333333c8.533333 6.4 19.2 10.666667 27.733333 10.666667 12.8 0 23.466667-4.266667 32-14.933333 14.933333-17.066667 14.933333-44.8-4.266667-59.733334L384 512z" p-id="14596"/>
        </svg>
        <span class="text-small">上一篇</span>
      </div>
      <div>深度学习——卷积神经网络——GoogLeNet</div>
    </a>
  
  <div class="vhr"></div>
  
    <a class="post-nav-item-right" href="/2022/03/20/VGG/">
      <div class="text-align">
        <span class="text-small">下一篇</span>
        <svg t="1670570876164"
             class="icon"
             viewBox="0 0 1024 1024"
             transform="scale(-1,-1)"
             width="16"
             height="16">
          <path d="M384 512L731.733333 202.666667c17.066667-14.933333 19.2-42.666667 4.266667-59.733334-14.933333-17.066667-42.666667-19.2-59.733333-4.266666l-384 341.333333c-10.666667 8.533333-14.933333 19.2-14.933334 32s4.266667 23.466667 14.933334 32l384 341.333333c8.533333 6.4 19.2 10.666667 27.733333 10.666667 12.8 0 23.466667-4.266667 32-14.933333 14.933333-17.066667 14.933333-44.8-4.266667-59.733334L384 512z" p-id="14596"/>
        </svg>
      </div>
      深度学习——卷积神经网络——VGG
    </a>
  
</div>

    
      <div class="related-post">
  <div class="related__head">
  
    <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-tag">#深度学习</a>
  
    <a href="/tags/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" class="post-tag">#卷积神经网络</a>
  
    <a href="/tags/%E5%8D%95GPU%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/" class="post-tag">#单GPU训练模型</a>
  
    <a href="/tags/NiN/" class="post-tag">#NiN</a>
  

</div>
  <div class="realated__body">
    
      <div class="null"><div class="null-item"><div class="null-title"><a href="/2022/02/20/AlexNet/" title="深度学习——卷积神经网络——AlexNet" rel="bookmark">深度学习——卷积神经网络——AlexNet</a></div></div><div class="null-item"><div class="null-title"><a href="/2022/06/20/Batch Normalization/" title="深度学习——卷积神经网络——Batch Normalization" rel="bookmark">深度学习——卷积神经网络——Batch Normalization</a></div></div><div class="null-item"><div class="null-title"><a href="/2022/05/20/GoogLeNet/" title="深度学习——卷积神经网络——GoogLeNet" rel="bookmark">深度学习——卷积神经网络——GoogLeNet</a></div></div><div class="null-item"><div class="null-title"><a href="/2020/07/20/AdaBoost与GBDT/" title="机器学习算法——AdaBoost与GBDT模型" rel="bookmark">机器学习算法——AdaBoost与GBDT模型</a></div></div><div class="null-item"><div class="null-title"><a href="/2021/01/20/K近邻算法/" title="机器学习算法——K近邻算法" rel="bookmark">机器学习算法——K近邻算法</a></div></div></div>
    
  </div>
</div>

    
    
      <div id="gitalk-container"></div>
    
  </div>

    </div>
    <div class="foot">
      <div class="foot-inner">
        <div class="foot__head">
          
            <div class="foot-line">
              <div class="matts">海</div><div class="matts">内</div><div class="matts">存</div><div class="matts">知</div><div class="matts">己</div>
            </div>
          
            <div class="foot-line">
              <div class="matts">天</div><div class="matts">涯</div><div class="matts">若</div><div class="matts">比</div><div class="matts">邻</div>
            </div>
          
        </div>
        <div class="foot__body">
          
            <div class="foot-item">
              <div class="foot-item__head">朋友</div>
              <div class="foot-item__body">
                
                  <div class="text">
                    <img alt="link"
                         height="20px"
                         width="20px"
                         src="/images/icon/icon-link.svg"/>
                    <a class="foot-link" target="_blank" rel="noopener" href="https://github.com/hooozen/hexo-theme-tranquility">Theme Tranquility</a>
                  </div>
                
                <div class="text">
                  <img alt="link"
                       height="20px"
                       width="20px"
                       src="/images/icon/icon-link+.svg"/>
                  <a class="foot-link"
                     href="mailto:jordanlee@stumail.hbu.edu.cn?subject=%E7%94%B3%E8%AF%B7%20Hozen.site%20%E7%9A%84%E5%8F%8B%E9%93%BE%E4%BD%8D%E7%BD%AE">
                  申请友链</a>
                </div>
              </div>
            </div>
          
          
            <div class="foot-item">
              <div class="foot-item__head">账号</div>
              <div class="foot-item__body">
                
                  <div class="text">
                    <img alt="link" height="20px" width="20px" src="/images/logo-github.svg"/>
                    <a class="foot-link" target="_blank" rel="noopener" href="https://github.com/Alchemiest">Alchemiest</a>
                  </div>
                
                  <div class="text">
                    <img alt="link" height="20px" width="20px" src="/images/logo-wx.svg"/>
                    <a class="foot-link" href="">松果篮</a>
                  </div>
                
                  <div class="text">
                    <img alt="link" height="20px" width="20px" src="/images/PNG图像 2.PNG"/>
                    <a class="foot-link" target="_blank" rel="noopener" href="https://b23.tv/qb0poEj">科学炼丹</a>
                  </div>
                
              </div>
            </div>
          
          <div class="foot-item">
            <div class="foot-item__head">联系</div>
            <div class="foot-item__body">
              <div class="text">
                <img alt="link"
                     height="20px"
                     width="20px"
                     src="/images/icon/icon-email.svg"/>
                <a class="foot-link" href="mailto:jordanlee@stumail.hbu.edu.cn">jordanlee@stumail.hbu.edu.cn</a>
              </div>
            </div>
          </div>
        </div>
        <div class="copyright">
          <a href="http://example.com">科学炼丹</a> &nbsp;|&nbsp;由&nbsp;<a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>&nbsp;及&nbsp;
          <svg width="20" height="20" viewBox="0 0 725 725">
            <path fill-rule="evenodd" fill="rgb(221, 221, 221)"
            d="M145.870,236.632 L396.955,103.578 L431.292,419.44 L156.600,522.53 L145.870,236.632 Z" />
            <path fill-rule="evenodd" fill="rgb(159, 159, 159)"
            d="M396.955,103.578 L564.345,234.486 L611.558,513.469 L431.292,419.44 L396.955,103.578 Z" />
            <path fill-rule="evenodd" fill="rgb(0, 0, 0)"
            d="M431.292,419.44 L611.558,513.469 L358.327,595.18 L156.600,522.53 L431.292,419.44 Z" />
          </svg>
          <a target="_blank" rel="noopener" href="https://github.com/hooozen/hexo-theme-tranquility">致远</a>&nbsp;驱动
        </div>
      </div>
    </div>
    
      <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    
    
  <script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
<script type="text/javascript">
  const param = JSON.parse('{"enable":true,"owner":"Alchemiest# MUST HAVE, Your Github Username","admin":null,"repo":"https://github.com/Alchemiest/Alchemiest.github.io# MUST HAVE, The name of the repo you use to store Gitment comments","clientID":"科学炼丹# MUST HAVE, Github client id for the Gitment","clientSecret":null,"distractionFreeMode":true,"proxy":"https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token","language":"zh-CN"}')
  param.id = location.pathname
  const gitalk = new Gitalk(param)
  gitalk.render('gitalk-container')
</script>

  
  
    <script type="text/javascript" src=/js/toc.js></script>
  

  </body>
</html>
